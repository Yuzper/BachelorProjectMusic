{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b39cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout, LSTM, TimeDistributed, BatchNormalization\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "#!pip install tensorflow==2.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c1bc4",
   "metadata": {},
   "source": [
    "# CRNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0399f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (235, 352, 4)\n",
    "\n",
    "# Define the CRNN architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Conv Block 1\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Conv Block 2\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Conv Block 3\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Recurrent layers\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "num_classes = 8\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7ce634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_spectrogram, y_train, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1aa7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6300ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1fae1bf",
   "metadata": {},
   "source": [
    "## Dataset split and load into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b3a8667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (7115, 2)\n",
      "Training Target Shape: (7115, 1)\n",
      "Testing Features Shape: (789, 2)\n",
      "Testing Target Shape: (789, 1)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "fma_small = pd.read_csv(\"fma_small.csv\")\n",
    "\n",
    "X_train = fma_small[fma_small[\"Set\"] == \"training\"][[\"ID\",\"Genre\"]]\n",
    "y_train = fma_small[fma_small[\"Set\"] == \"training\"][[\"Genre\"]]\n",
    "\n",
    "X_test = fma_small[fma_small[\"Set\"] == \"test\"][[\"ID\",\"Genre\"]]\n",
    "y_test = fma_small[fma_small[\"Set\"] == \"test\"][[\"Genre\"]]\n",
    "\n",
    "# print the shapes of the new datasets\n",
    "print(\"Training Features Shape:\", X_train.shape)\n",
    "print(\"Training Target Shape:\", y_train.shape)\n",
    "print(\"Testing Features Shape:\", X_test.shape)\n",
    "print(\"Testing Target Shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to set all pixel values between 0 and 1.\n",
    "def normalize_image(path):\n",
    "    image = Image.open(path)\n",
    "    pixels = asarray(image)\n",
    "    # convert from integers to floats\n",
    "    pixels = pixels.astype(\"float32\")\n",
    "    # normalize to the range 0-1\n",
    "    pixels /= 255.0\n",
    "    # confirm the normalization\n",
    "    #print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "    return pixels\n",
    "\n",
    "\n",
    "\n",
    "# Loading data into RAM\n",
    "train_spectrogram = []\n",
    "test_spectrogram = []\n",
    "#fma_small = pd.read_csv(\"fma_small.csv\")\n",
    "\n",
    "for train_id in X_train[\"ID\"]:\n",
    "    for filename in os.listdir(\"SpectrogramData\"):\n",
    "        if filename.endswith(\".png\"): # Not checking directories\n",
    "            fileID = int(filename.split(\".\")[0]) # Extract ID from filename\n",
    "            if train_id == fileID:\n",
    "                path = \"SpectrogramData\"+\"/\"+str(filename)\n",
    "                normalized_img = normalize_image(path)\n",
    "                train_spectrogram.append(np.array(normalized_img))\n",
    "\n",
    "for test_id in X_test[\"ID\"]:\n",
    "    for filename in os.listdir(\"SpectrogramData\"):\n",
    "        if filename.endswith(\".png\"): # Not checking directories\n",
    "            fileID = int(filename.split(\".\")[0]) # Extract ID from filename\n",
    "            if test_id == fileID:\n",
    "                path = \"SpectrogramData\"+\"/\"+str(filename)\n",
    "                normalized_img = normalize_image(path)\n",
    "                test_spectrogram.append(np.array(normalized_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849342cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Data:\",len(train_spectrogram))\n",
    "print(\"Test Data:\",len(test_spectrogram))\n",
    "len(train_spectrogram)//len(test_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking the numpy arrays to format to the CNN models requirements\n",
    "train_spectrogram = np.stack(train_spectrogram, axis=0)\n",
    "test_spectrogram = np.stack(test_spectrogram, axis=0)\n",
    "train_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edab2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encodes the genres for the CNN\n",
    "y_train = np.array(pd.get_dummies(y_train))\n",
    "y_test = np.array(pd.get_dummies(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5650484e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ac1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines function for model artitecture:\n",
    "def create_model(n_filters, kernel_sizes, pool_sizes, lstm_units, dropout_rate): # 5 Hyperparameters\n",
    "    # Define the input shape\n",
    "    input_shape = (235, 352, 4)\n",
    "\n",
    "    # Define the CRNN architecture\n",
    "    model = Sequential()\n",
    "\n",
    "    # Conv Block 1\n",
    "    model.add(Conv2D(filters=n_filters[0], kernel_size=kernel_sizes, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(MaxPool2D(pool_size=pool_sizes))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Conv Block 2\n",
    "    model.add(Conv2D(filters=n_filters[1], kernel_size=kernel_sizes, activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=pool_sizes))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Conv Block 3\n",
    "    model.add(Conv2D(filters=n_filters[2], kernel_size=kernel_sizes, activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=pool_sizes))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Recurrent layers\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(GRU(lstm_units*2, return_sequences=True))\n",
    "    model.add(GRU(lstm_units))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    num_classes = 8\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "# Step 3: Create a GridSearchCV object and specify the hyperparameters to tune\n",
    "model = KerasClassifier(build_fn=create_model, n_filters=(16, 32, 64), kernel_sizes=(3, 3), pool_sizes=(2, 2), lstm_units=32, dropout_rate=0.1)\n",
    "\n",
    "# n_filters, kernel_sizes, pool_sizes, lstm_units, dropout_rate\n",
    "#hyperparams = {\"n_filters\": [(16,32,64), (32,64,128),(64,128,256)],\n",
    "#               \"kernel_sizes\": [(3,3), (4,4)],\n",
    "#               \"pool_sizes\": [(2,2),(3,3)],\n",
    "#               \"lstm_units\": [32,64,128],\n",
    "#               \"dropout_rate\": [0.1, 0.3, 0.5]\n",
    "#              }\n",
    "\n",
    "hyperparams = {\"n_filters\": [(2,4,6)],\n",
    "               \"kernel_sizes\": [(3,3)],\n",
    "               \"pool_sizes\": [(2,2)],\n",
    "               \"lstm_units\": [8],\n",
    "               \"dropout_rate\": [0.1]\n",
    "              }\n",
    "\n",
    "#grid = GridSearchCV(estimator=model, param_grid=hyperparams, cv=5, verbose=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=hyperparams, cv=2, verbose=1)\n",
    "\n",
    "# Step 4: Fit the GridSearchCV object to your data\n",
    "#grid_result = grid.fit(train_generator, steps_per_epoch=100)\n",
    "grid_result = grid.fit(train_spectrogram, y_train, epochs=1, steps_per_epoch=10)\n",
    "\n",
    "\n",
    "# Step 5: Retrieve the best hyperparameters and train your final model\n",
    "best_params = grid.best_params_\n",
    "final_model = create_model(**best_params)\n",
    "final_model.fit(train_spectrogram, y_train, steps_per_epoch=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96668362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db457938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8dade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76d7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1152e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
